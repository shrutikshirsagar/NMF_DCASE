{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "necessary-falls",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 48)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "out = '/media/amrgaballah/Backup_Plus/DCASE2021_SELD_dataset/seld_feat_all/foa/mel_feat_foa_0.02/seld_feat_label/foa_dev_label/fold1_room1_mix001.npy'\n",
    "\n",
    "a = np.load(out)\n",
    "print(a.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "strategic-covering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold6_room2_mix050.npy\n",
      "fold6_room2_mix049.npy\n",
      "fold6_room2_mix048.npy\n",
      "fold6_room2_mix047.npy\n",
      "fold6_room2_mix046.npy\n",
      "fold6_room2_mix045.npy\n",
      "fold6_room2_mix044.npy\n",
      "fold6_room2_mix043.npy\n",
      "fold6_room2_mix042.npy\n",
      "fold6_room2_mix041.npy\n",
      "fold6_room2_mix040.npy\n",
      "fold6_room2_mix039.npy\n",
      "fold6_room2_mix038.npy\n",
      "fold6_room2_mix037.npy\n",
      "fold6_room2_mix036.npy\n",
      "fold6_room2_mix035.npy\n",
      "fold6_room2_mix034.npy\n",
      "fold6_room2_mix033.npy\n",
      "fold6_room2_mix032.npy\n",
      "fold6_room2_mix031.npy\n",
      "fold6_room2_mix030.npy\n",
      "fold6_room2_mix029.npy\n",
      "fold6_room2_mix028.npy\n",
      "fold6_room2_mix027.npy\n",
      "fold6_room2_mix026.npy\n",
      "fold6_room2_mix025.npy\n",
      "fold6_room2_mix024.npy\n",
      "fold6_room2_mix023.npy\n",
      "fold6_room2_mix022.npy\n",
      "fold6_room2_mix021.npy\n",
      "fold6_room2_mix020.npy\n",
      "fold6_room2_mix019.npy\n",
      "fold6_room2_mix018.npy\n",
      "fold6_room2_mix017.npy\n",
      "fold6_room2_mix016.npy\n",
      "fold6_room2_mix015.npy\n",
      "fold6_room2_mix014.npy\n",
      "fold6_room2_mix013.npy\n",
      "fold6_room2_mix012.npy\n",
      "fold6_room2_mix011.npy\n",
      "fold6_room2_mix010.npy\n",
      "fold6_room2_mix009.npy\n",
      "fold6_room2_mix008.npy\n",
      "fold6_room2_mix007.npy\n",
      "fold6_room2_mix006.npy\n",
      "fold6_room2_mix005.npy\n",
      "fold6_room2_mix004.npy\n",
      "fold6_room2_mix003.npy\n",
      "fold6_room2_mix002.npy\n",
      "fold6_room2_mix001.npy\n",
      "fold6_room1_mix050.npy\n",
      "fold6_room1_mix049.npy\n",
      "fold6_room1_mix048.npy\n",
      "fold6_room1_mix047.npy\n",
      "fold6_room1_mix046.npy\n",
      "fold6_room1_mix045.npy\n",
      "fold6_room1_mix044.npy\n",
      "fold6_room1_mix043.npy\n",
      "fold6_room1_mix042.npy\n",
      "fold6_room1_mix041.npy\n",
      "fold6_room1_mix040.npy\n",
      "fold6_room1_mix039.npy\n",
      "fold6_room1_mix038.npy\n",
      "fold6_room1_mix037.npy\n",
      "fold6_room1_mix036.npy\n",
      "fold6_room1_mix035.npy\n",
      "fold6_room1_mix034.npy\n",
      "fold6_room1_mix033.npy\n",
      "fold6_room1_mix032.npy\n",
      "fold6_room1_mix031.npy\n",
      "fold6_room1_mix030.npy\n",
      "fold6_room1_mix029.npy\n",
      "fold6_room1_mix028.npy\n",
      "fold6_room1_mix027.npy\n",
      "fold6_room1_mix026.npy\n",
      "fold6_room1_mix025.npy\n",
      "fold6_room1_mix024.npy\n",
      "fold6_room1_mix023.npy\n",
      "fold6_room1_mix022.npy\n",
      "fold6_room1_mix021.npy\n",
      "fold6_room1_mix020.npy\n",
      "fold6_room1_mix019.npy\n",
      "fold6_room1_mix018.npy\n",
      "fold6_room1_mix017.npy\n",
      "fold6_room1_mix016.npy\n",
      "fold6_room1_mix015.npy\n",
      "fold6_room1_mix014.npy\n",
      "fold6_room1_mix013.npy\n",
      "fold6_room1_mix012.npy\n",
      "fold6_room1_mix011.npy\n",
      "fold6_room1_mix010.npy\n",
      "fold6_room1_mix009.npy\n",
      "fold6_room1_mix008.npy\n",
      "fold6_room1_mix007.npy\n",
      "fold6_room1_mix005.npy\n",
      "fold6_room1_mix004.npy\n",
      "fold6_room1_mix003.npy\n",
      "fold6_room1_mix002.npy\n",
      "fold6_room1_mix001.npy\n",
      "fold6_room1_mix006.npy\n",
      "(60000, 496)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "final_vec = np.empty((0, 448))\n",
    "out1 = '/media/amrgaballah/Backup_Plus/DCASE2021_SELD_dataset/seld_feat_all/foa/mel_feat_foa_0.02/seld_feat_label/foa_dev_norm_label/'\n",
    "for filename1 in os.listdir(out1):\n",
    "    \n",
    "    if filename1.startswith('fold1'):\n",
    "        filename = os.path.join(out1, filename1)\n",
    "        print(filename1)\n",
    "        a = np.load(filename)\n",
    "        a1 = a[:, :-36]\n",
    "        print(a1.shape)\n",
    "        b1\n",
    "        final_vec = np.vstack((final_vec, a))\n",
    "print(final_vec.shape)\n",
    "np.save('/media/amrgaballah/Backup_Plus/DCASE2021_SELD_dataset/fold61.npy', final_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "returning-laser",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.load('/media/amrgaballah/Backup_Plus/DCASE2021_SELD_dataset/fold6.npy')\n",
    "print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-japan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "martial-enhancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, scale\n",
    "\n",
    "from beta_ntf import BetaNTF\n",
    "from tnmf import SupervisedDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "completed-partnership",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec1 = np.load('/media/amrgaballah/Backup_Plus/DCASE2021_SELD_dataset/fold11.npy')\n",
    "vec2 = np.load('/media/amrgaballah/Backup_Plus/DCASE2021_SELD_dataset/fold21.npy')\n",
    "vec3 = np.load('/media/amrgaballah/Backup_Plus/DCASE2021_SELD_dataset/fold31.npy')\n",
    "vec4 = np.load('/media/amrgaballah/Backup_Plus/DCASE2021_SELD_dataset/fold41.npy')\n",
    "X_train = np.vstack((vec1,vec2,vec3,vec4))\n",
    "np.save('/media/amrgaballah/Backup_Plus/DCASE2021_SELD_dataset/fold71.npy', X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "liquid-rebate",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train = np.load('/media/amrgaballah/Backup_Plus/DCASE2021_SELD_dataset/fold71.npy')\n",
    "X_test = np.load('/media/amrgaballah/Backup_Plus/DCASE2021_SELD_dataset/fold61.npy')\n",
    "X_valid = np.load('/media/amrgaballah/Backup_Plus/DCASE2021_SELD_dataset/fold51.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "friendly-military",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting NTF model with 100 iterations....\n",
      "Done.\n",
      "Fitting NTF model with 100 iterations....\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (60000,496) (60000,448) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-d11342ba3559>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mnmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_factors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mnmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactors_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mW_uns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mnmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mH_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactors_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/TGNMF-master/beta_ntf.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, W)\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0mrequest\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mascii_lowercase\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'z'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0;31m# building data-dependent factors for the update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                 \u001b[0moperand_data_numerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m                 \u001b[0moperand_data_denominator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mW\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                 \u001b[0;31m# compute numerator and denominator for the update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (60000,496) (60000,448) "
     ]
    }
   ],
   "source": [
    "nmf = BetaNTF(data_shape=X_train[:,:-48].shape, n_components=10, n_iter=100, verbose=False, beta=2)\n",
    "nmf.fit(X_train[:,:-48])\n",
    "W_uns = nmf.factors_[1]\n",
    "H_train = nmf.factors_[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-beatles",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "structural-modern",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting NTF model with 100 iterations....\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "nmf = BetaNTF(data_shape=X_test[:,:-48].shape, n_components=10, n_iter=100, verbose=False, beta=2)\n",
    "nmf.fixed_factors = [1]\n",
    "nmf.factors_[1]  = W_uns\n",
    "nmf.fit(X_test[:,:-48])\n",
    "H_test = nmf.factors_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "documented-jewelry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting NTF model with 100 iterations....\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "nmf = BetaNTF(data_shape=X_text.shape, n_components=10, n_iter=100, verbose=False, beta=2)\n",
    "nmf.fixed_factors = [1]\n",
    "nmf.factors_[1]  = W_uns\n",
    "nmf.fit(X_text)\n",
    "H_test = nmf.factors_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "everyday-devices",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting NTF model with 100 iterations....\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "nmf = BetaNTF(data_shape=X_valid[:,:-48].shape, n_components=10, n_iter=100, verbose=False, beta=2)\n",
    "nmf.fixed_factors = [1]\n",
    "nmf.factors_[1]  = W_uns\n",
    "nmf.fit(X_valid[:,:-48])\n",
    "H_valid = nmf.factors_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ultimate-bacon",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/media/amrgaballah/Backup_Plus/DCASE2021_SELD_dataset/H_test1.npy', H_test)\n",
    "np.save('/media/amrgaballah/Backup_Plus/DCASE2021_SELD_dataset/H_train1.npy', H_train)\n",
    "np.save('/media/amrgaballah/Backup_Plus/DCASE2021_SELD_dataset/H_valid1.npy', H_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-amateur",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
